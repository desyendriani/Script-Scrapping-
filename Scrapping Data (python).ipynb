{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d83f46e",
      "metadata": {
        "id": "3d83f46e"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fcb317",
      "metadata": {
        "id": "38fcb317"
      },
      "outputs": [],
      "source": [
        "!pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a919008",
      "metadata": {
        "id": "7a919008"
      },
      "outputs": [],
      "source": [
        "!pip install tweepy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3fad20",
      "metadata": {
        "id": "bd3fad20"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "\n",
        "client = tweepy.Client(bearer_token = \"XXXXXXXXXX", wait_on_rate_limit=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e544ab",
      "metadata": {
        "id": "a8e544ab"
      },
      "outputs": [],
      "source": [
        "hoax_tweets[0].data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da64adf",
      "metadata": {
        "id": "0da64adf"
      },
      "outputs": [],
      "source": [
        "hoax_tweets[0].includes['users'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c492d6",
      "metadata": {
        "id": "11c492d6"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "user_dict = {}\n",
        "# Loop through each response object\n",
        "for response in hoax_tweets:\n",
        "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
        "    for user in response.includes['users']:\n",
        "        user_dict[user.id] = {'username': user.username, \n",
        "                              'followers': user.public_metrics['followers_count'],\n",
        "                              'tweets': user.public_metrics['tweet_count'],\n",
        "                              'description': user.description,\n",
        "                              'location': user.location\n",
        "                             }\n",
        "    for tweet in response.data:\n",
        "        # For each tweet, find the author's information\n",
        "        author_info = user_dict[tweet.author_id]\n",
        "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
        "        result.append({'author_id': tweet.author_id, \n",
        "                       'username': author_info['username'],\n",
        "                       'author_followers': author_info['followers'],\n",
        "                       'author_tweets': author_info['tweets'],\n",
        "                       'author_description': author_info['description'],\n",
        "                       'author_location': author_info['location'],\n",
        "                       'text': tweet.text,\n",
        "                       'created_at': tweet.created_at,\n",
        "                       'retweets': tweet.public_metrics['retweet_count'],\n",
        "                       'replies': tweet.public_metrics['reply_count'],\n",
        "                       'likes': tweet.public_metrics['like_count'],\n",
        "                       'quote_count': tweet.public_metrics['quote_count']\n",
        "                      })\n",
        "\n",
        "# Change this list of dictionaries into a dataframe\n",
        "df = pd.DataFrame(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "683ac9b8",
      "metadata": {
        "id": "683ac9b8"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee4fb19",
      "metadata": {
        "id": "4ee4fb19"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"PPKM.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "_Ycsq6tMZu51"
      },
      "id": "_Ycsq6tMZu51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "0wRPlXdqZvDY"
      },
      "id": "0wRPlXdqZvDY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"gdrive/MyDrive/skripsi revisi/\"\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "id": "hDSVfrpUZ_SY"
      },
      "id": "hDSVfrpUZ_SY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(path+\"PPKM1.csv\")"
      ],
      "metadata": {
        "id": "QA9dCN5DZ_VZ"
      },
      "id": "QA9dCN5DZ_VZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('PPKM.csv')"
      ],
      "metadata": {
        "id": "g681rTx5geUH"
      },
      "id": "g681rTx5geUH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df"
      ],
      "metadata": {
        "id": "KXxqhH_9gjat"
      },
      "id": "KXxqhH_9gjat",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string, re\n",
        "\n",
        "def cleansing(data):\n",
        "    # lower text\n",
        "    data = data.lower()\n",
        "    \n",
        "    # hapus punctuation\n",
        "    remove = string.punctuation\n",
        "    translator = str.maketrans(remove, ' '*len(remove))\n",
        "    data = data.translate(translator)\n",
        "    \n",
        "    # remove ASCII dan unicode\n",
        "    data = data.encode('ascii', 'ignore').decode('utf-8')\n",
        "    data = re.sub(r'[^\\x00-\\x7f]',r'', data)\n",
        "    data = re.sub(r\"http\\S+\", '', data) # remove link\n",
        "    # remove newline\n",
        "    data = data.replace('\\n', ' ')\n",
        "    \n",
        "    return data"
      ],
      "metadata": {
        "id": "cr5q2t2Cjpn2"
      },
      "id": "cr5q2t2Cjpn2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# jalankan cleansing data\n",
        "review = []\n",
        "for index, row in data.iterrows():\n",
        "    review.append(cleansing(row[\"text\"]))\n",
        "    \n",
        "data['text'] = review\n",
        "data = pd.DataFrame(data)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Dnggnbqej2Jh"
      },
      "id": "Dnggnbqej2Jh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=text[['author_location','text','created_at']]\n",
        "text"
      ],
      "metadata": {
        "id": "ocfdNNusktze"
      },
      "id": "ocfdNNusktze",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
        "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
        "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
        "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
        "\n",
        "    text = text.replace('\\n', ' ') # replace new line into space\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
        "    text = text.strip(' ') # remove characters space from both left and right text\n",
        "    return text "
      ],
      "metadata": {
        "id": "Aq1iqzfTlKja"
      },
      "id": "Aq1iqzfTlKja",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text['text'] = text['text'].apply(cleaningText)"
      ],
      "metadata": {
        "id": "zPYQQVIwmYTY"
      },
      "id": "zPYQQVIwmYTY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "XM_j1Yazl_Gv"
      },
      "id": "XM_j1Yazl_Gv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "crawling revisi.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
